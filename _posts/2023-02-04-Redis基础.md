---
title: Redis基础
date: 2023-02-04 20:14:15 +0800 
categories: [storage, Redis]
tags: [history, Redis, middleware, storage] 
---

### 一、基础知识
#### 常识：

- 磁盘 寻址：ms 带宽：G/M
- 内存 寻址：ns 带宽：很大
- I/O Buffer：成本问题 磁盘、磁道，一个扇区512Btye 带来一个成本变大：索引 4K 操作系统，无论读多少，从磁盘拿最少4K

**磁盘比内存慢了10W倍**

***java随着文件的变大，速度变慢，磁盘I/O成为瓶颈***

#### 关系型数据库

​ 建表必须给出schema ​ 类型：字节宽度 ​ 存储：倾向于行级存储 ​ ***问题***

- 表很大，性能下降？ 如果表有索引，增删改变慢，维护索引耗时
- 查询速度？
    - 1个或少量依然很快
    - 并发大的时候受硬盘带宽影响速度

#### 非关系型数据库 （Redis、Memcached）

#### **比Memcached(key,value)的优势**

- Memecached中value 没有类型（通过json表示复杂的数据结构）
- 缓存（k,v）中取回v中一个元素成本消耗不同
    - 类型不是很重要，redis的server中对每种类型都有自己的方法取回value中的某个元素
    - Memcached返回value数据到client，对网卡IO有要求，client要有实现代码去解析提取数据

#### Redis为什么快

**了解IO**

![Redis.png](/assets/img/2023-02-04-Redis基础/Redis.png)

IO演进  
**BIO** : socket在没有数据时，被阻塞，每阻塞一个抛出一个线程等待数据;(一个线程的成本1MB,线程多了，调度成本高了,内存成本大了)  
**NIO** : 内核改进,Linux命令：`man 2 read`, 内核socket的fd可以是`nonblock`, 用户空进行轮询，反复询问内核数据是否准备完成，完成读取(存在成本问题，如果有1000fd，用户进程轮询调用1000次kernel)  
**多路复用NIO**: `select`内核监控所有的fd，轮询，如果某个fd数据准备完成，进行read到用户空间，减少用户空间和内核空间的切换(存在问题，数据和fd从内核态和用户态考来考去，最后经过网卡发送，还是很复杂)  
**epoll**: 用户态和内核态有共享空间,通过mmap实现+数据结构+红黑树, 进程通过`epoll`将fd写入共享空间，放入红黑树+链表结构，当数据准备完成，产生系统中断，将内核将fd放入链表中，进程再用户态直接通过共享空间读（零拷贝）`sendfile（out , in）` , `kafka mmap sendfile`, linux中没有AIO，只有windows中有AIO；单进程，并发的时候，是一个个处理 ​ “顺序”的，具体顺序看负载均衡的情况。

epoll ​ 共享空间中直接取，同步非阻塞，多路复用

#### 数据类型
#### 1、String
##### 1）String类型

**k-v** 键值对

##### 2）数值

incr、decr

抢购，秒杀，详情页，点赞，评论

规避并发下，对数据库的事务操作完全由redis内存操作代替

##### 3）bitmap的用法

- 有用户系统，统计用户登录天数，且窗口随机
    
    ![redis统计登录天数-1598932010783.JPG](/assets/img/2023-02-04-Redis基础/redis统计登录天数-1598932010783.jpg)
    
    统计用户的登录天数
    
- **618就是做活动；送礼物，大库备货多少礼物；假设京东有2E用户**
    
    僵尸用户
    
    冷热用户/忠诚用户
    
    活跃用户统计！随机窗口
    
    例如1-3号联系登录， 去重，去掉重复用户bit
    
    ![统计一段时间内登录用户人数.JPG](/assets/img/2023-02-04-Redis基础/统计一段时间内登录用户人数.jpg)
    
    统计一段时间内登录用户人数
    

#### 2、List（有序）(quickList = zipList + linkedList)
##### 1）队列  
##### 2）栈  
##### 3）数组  
##### 4）阻塞，单播队列FIFO  

#### 3、Hash (zipList hashtable + 增量式hash)

（map）k-v 键值对，标识一个对象。可单独取出其中一个Field进行操作。

使用场景：点赞、收藏、详情页

#### 4、Set
##### 1）无序去重

【无序】&&【随机性】

放入的多少不同， 元素存储的舒徐不同

【去重】

##### 2）集合操作（交、并、差等）

用处：关注，查看两个人的共同关注等

##### 3）随机事件（抽奖，是否能重复抽奖，奖数 > | < 人数情况）

- SRANDMEMBER KEY [COUNT]
    - **count为正数**：取出一个去重的结果集（不能超过已有集）  
    取出不重复的集合  
    ![取出不重复的集合.JPG](/assets/img/2023-02-04-Redis基础/取出不重复的集合.jpg)
    
    - **count为负数**：取出一个带重复的结果集，一定能满足数量的需求  
     取带重复的结果集  
     ![取带重复的结果集.JPG](/assets/img/2023-02-04-Redis基础/取带重复的结果集.jpg)
        
    - **count为0**：0，不返回  
     随机取0  
     ![随机取0-1598933826813.JPG](/assets/img/2023-02-04-Redis基础/随机取0-1598933826813.jpg)
        
- SPOP：每次取出一个，并从集合中删除已有值，（公司年终抽奖）  
    取出不放回  
    ![取出不放回.JPG](/assets/img/2023-02-04-Redis基础/取出不放回.jpg)
  
#### 5、ZSet （skipList）

##### 1）特点

有序的Set，一个节点包含：**元素**，**score**，**索引**（有逆向索引）  

首先按**score**排序，如果score相同，则按**字典序**，且==在物理内存中，是从小到大排序的==；可以按照**score和索引两种方式**取元素。

**score**是可以改变的，**用作排行榜**。

##### 2）带分值（score）集合操作

例如，取并集，可选择将score相加、权重、最小值、最大值。（默认相加）

##### 3）排序是如何实现的？增删改查的速度如何？

#### **skiplist（跳跃表）**

### 二、Redis持久化方式RDB和AOF的区别，优势劣势

#### 1、前言

最近在项目中使用到Redis做缓存，方便多个业务进程之间共享数据。由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化，一种是RDB持久化（**原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化**），另外一种是AOF持久化（**原理是将Reids的操作日志以追加的方式写入文件**）。

#### 2、区别

**RDB**：RDB持久化是指在指定的时间间隔内将内存中的数据集**快照/副本**写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。

- **时点性**，可能丢失数据，**时点混乱问题**
- 非阻塞：在对外提供服务时 写磁盘，持久化操作

**AOF**：AOF持久化以**日志**的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。

#### 3、二者优缺点

**RDB存在哪些优势呢？**

- **一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。**比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。
- **对于灾难恢复而言，RDB是非常不错的选择。**因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。
- **性能最大化。**对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。
- **相比于AOF机制，如果数据集很大，RDB的启动效率会更高。**

**RDB又存在哪些劣势呢？**

- ***数据可能丢失。***如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。
- ***持久化过程占用太长时间。***由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。
- ***不支持拉链，只有一个dump.rdb***

**AOF的优势有哪些呢？**

- ***该机制可以带来更高的数据安全性，即数据持久性***。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。
- 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只写入了一半数据就出现了系统崩溃问题，在Redis下一次启动之前，我们可以**通过redis-check-aof工具来帮助我们解决数据一致性的问题。**
- **如果日志过大，Redis可以自动启用rewrite机制。**即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。
- **AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。**事实上，我们也可以通过该文件完成数据的重建。

**AOF的劣势有哪些呢？**

1)**对于相同数量的数据集而言，AOF文件通常要大于RDB文件。**RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

2)**根据同步策略的不同，AOF在运行效率上往往会慢于RDB。**总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。**不过生产环境其实更多都是二者结合使用的。**

#### 4、常用配置

##### RDB持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息：（此出的save 其实是**bgsave**）

- **save 900 1** #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。
- **save 300 10** #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。
- **save 60 10000** #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

##### AOF持久化配置

在Redis的配置文件中存在三种同步方式，它们分别是：

- **appendfsync always** #每次有数据修改发生时都会写入AOF文件。
- **appendfsync everysec** #每秒钟同步一次，该策略为AOF的缺省策略。
- **appendfsync no** #从不同步。高效但是数据不会被持久化。

#### 补充：Linux

linux fork 创建子进程， copy on write，写时复制，**加快进程的创建**

先写内存， 然后由指针指向物理内存

父子进程，常规思想，进程数据是隔离的（内存映射是隔离的）。

---

### 三、Redis实现锁、分布式锁

#### 1、Redis单机锁 *setnx*

1、setnx + expire 要在同一行才是原子操作，加过期时间防止获得锁后，出错无法释放造成死锁  
2、过期时间expiretime需要定期延长，防止时间到了，线程还未运行结束。延长方案：  
**过期时间位n，创建子线程，每过n/3秒，将过期时间延长到n**  
3、避免释放别人的锁，创建key时，再设置value为司机的id，自己只能释放自己的锁。
**释放别人的锁情况：**  
> A线程获得了锁，宕机了，过期时间到了，锁自动释放；然后B线程获得锁，此时，A线程恢复，继续执行，释放了B的锁。
    
4、redis单机用这个完全没有问题，但是又造成了单机故障，因此引入了Redis分布式锁。

#### 2、Redis分布式锁 *红锁* —- RedLock（多master）
debug
> 断点达到：`rLock.lock()`执行完后，看结果，发现如果是3个redis节点，则有2个节点中设置了值。

**目的：对共享资源做互斥访问。**  
提出了分布式锁的算法Redlock，它基于N个完全独立的Redis节点（通常情况N可以设置成5）。  
运行Redlock算法的客户端依次执行下面各个步骤，来完成 获取锁 的操作：  
1、获取当前时间（毫秒数）。  
2、按顺序依次向N个Redis节点执行 **获取锁** 的操作。这个获取操作跟前面基于单Redis节点的 **获取锁** 的过程相同，包含value driverId ，也包含过期时间(比如 `PX 30000` ，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个 **获取锁** 的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。  
3、计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（>= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。  
4、如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。  
5、如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起 **释放锁** 的操作（即前面介绍的Redis Lua脚本）。  

当然，上面描述的只是 获取锁 的过程，而 释放锁 的过程比较简单：客户端向所有Redis节点发起 释放锁 的操作，不管这些节点当时在获取锁的时候成功与否。

**问题：**  
由于N个Redis节点中的大多数能正常工作就能保证Redlock正常工作，因此理论上它的可用性更高。我们前面讨论的单Redis节点的分布式锁在failover的时候锁失效的问题，在Redlock中不存在了，但如果有节点发生崩溃重启，还是会对锁的安全性有影响的。**具体的影响程度跟Redis对数据的持久化程度有关。**

假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：

1. 客户端1成功锁住了A, B, C， **获取锁** 成功（但D和E没有锁住）。
2. 节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。
3. 节点C重启后，客户端2锁住了C, D, E， **获取锁** 成功。

这样，客户端1和客户端2同时获得了锁（针对同一资源）。

在默认情况下，Redis的AOF持久化方式是每秒写一次磁盘（即执行fsync），因此最坏情况下可能丢失1秒的数据。为了尽可能不丢数据，Redis允许设置成每次修改数据都进行fsync，但这会降低性能。当然，即使执行了fsync也仍然有可能丢失数据（这取决于系统而不是Redis的实现）。所以，上面分析的由于节点重启引发的锁失效问题，总是有可能出现的。为了应对这一问题，antirez又提出了 延迟重启 (delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。

关于Redlock还有一点细节值得拿出来分析一下：在最后 释放锁 的时候，antirez在算法描述中特别强调，客户端应该向所有Redis节点发起 释放锁 的操作。也就是说，即使当时向某个节点获取锁没有成功，在释放锁的时候也不应该漏掉这个节点。这是为什么呢？设想这样一种情况，客户端发给某个Redis节点的 获取锁 的请求成功到达了该Redis节点，这个节点也成功执行了 `SET`操作，但是它返回给客户端的响应包却丢失了。这在客户端看来，获取锁的请求由于超时而失败了，但在Redis这边看来，加锁已经成功了。因此，释放锁的时候，客户端也应该对当时获取锁失败的那些Redis节点同样发起请求。实际上，这种情况在异步通信模型中是有可能发生的：客户端向服务器通信是正常的，但反方向却是有问题的。

---

### 四、Redis缓存和Mysql数据库的问题

不管是**先写MySQL数据库，再删除Redis缓存**；还是**先删除缓存，再写库**，都有可能出现数据不一致的情况。举一个例子：

- 如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。
- 如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。

#### 缓存和数据库一致性解决方案

##### 1、延时双删策略

在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。  
伪代码如下：
```java
public void write(String key,Object data) {    
     redis.delKey(key);     
     db.updateData(data);     
     Thread.sleep(500);     
     redis.delKey(key);
}
```

**具体的步骤就是：**
- 先删除缓存；
- 再写数据库；
- 休眠500毫秒；
- 再次删除缓存。

**那么，这个500毫秒怎么确定的，具体该休眠多久呢？**

需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。

**设置缓存过期时间**

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

**==该方案的弊端==**

结合双删策略+缓存超时设置，最差的情况就是**在超时时间内数据存在不一致**，而且又增加了**写请求**的耗时。

##### 2、`bin log`异步更新缓存

**技术整体思路：**

MySQL **`bin log`**增量订阅消费+消息队列+增量数据更新到redis

- **读Redis**：热数据基本都在Redis
- **写MySQL**:增删改都是操作MySQL
- **更新Redis数据**：MySQL的数据操作**`bin log`**，来更新到Redis

**Redis更新**

**1）数据操作主要分为两大块：**

- 一个是全量(将全部数据一次写入到redis)
- 一个是**增量**（实时更新）

这里说的是增量,指的是mysql的update、insert、delate变更数据。

**2）读取`bin log`后分析 ，利用消息队列,推送更新各台的redis缓存数据。**

这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把**`bin log`**相关的消息推送至Redis，Redis再根据**`bin log`**中的记录，对Redis进行更新。

其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过**`bin log`**来实现的数据一致性。

这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的**`bin log`**进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。

当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。

##### 3、==内存队列==的方式

依靠内存队列将同一个id的请求串行化操作，保证了强一致性，但是大大降低了性能

---

#### Redis缓存存在问题

##### 1、缓存穿透

###### 布隆过滤器 （bloom过滤器）

按概率解决问题，有**不到1%**的概率击穿缓存

**存在问题：**

- 恰巧是那1%的情况击穿了，在client端添加业务，访问一次后，穿透bloom过滤器，mysql不存在，在redis缓存中添加 **击穿的key，value标记**
- 数据库增加了元素，完成对bloom的添加，双写一致性的问题
- 数据库删除数据，bloom过滤器无法处理，可考虑 **升级版counting bloom**

###### 布谷鸟过滤器

##### 2、缓存击穿

缓存击穿意味着当热点数据存储到期时，多个线程同时请求热点数据。因为缓存刚过期，所有并发请求都会到数据库查询数据。

解： 实际上，在大多数实际业务场景中，缓存击穿是实时发生的，但不会对数据库造成太大压力，因为一般的公司业务，并发量不会那么高。当然如果你不幸有这种情况，你可以通过设置这些热点键，使其永远不会过期。另一种方法是通过互斥锁来控制查询数据库的线程访问，但这种会导致系统的吞吐率下降，需要实际情况使用。

##### 3、缓存雪崩

数据未加载到缓存中，或者缓存同时在大范围中失效，导致所有请求查找数据库，导致数据库、CPU 和内存过载，甚至停机。 一个简单的雪崩过程： 1） Redis 集群的大面积故障； 2） 缓存失败，但仍有大量请求访问缓存服务 Redis； 3） 在大量 Redis 请求失败后，请求转向数据库； 4） 数据库请求急剧增加，导致数据库被打死； 5） 由于你应用程序服务大部分都依赖于数据库和 Redis 服务，它很快就会导致服务器集群的雪崩，最后整个系统将彻底崩溃。 **解**： 事前：高可用的缓存 高可用的缓存是防止出现整个缓存故障。即使个别节点，机器甚甚至机房都关闭，系统仍然可以提供服务，Redis 哨兵(Sentinel) 和 Redis 集群(Cluster) 都可以做到高可用。 事中：缓存降级（临时支持） 当访问次数急剧增加导致服务出现问题时，我们如何确保服务仍然可用。在国内使用比较多的是 Hystrix，它通过熔断、降级、限流三个手段来降低雪崩发生后的损失。只要确保数据库不死，系统总可以响应请求，每年的春节 12306 我们不都是这么过来的吗？只要还可以响应起码还有抢到票的机会。 事后：Redis 备份和快速预热 1） Redis 数据备份和恢复 2） 快速缓存预热

###### 使用Hystrix

Hystrix是一款开源的“防雪崩工具”，它通过 熔断、降级、限流三个手段来降低雪崩发生后的损失。

Hystrix就是一个Java类库，它采用命令模式，每一项服务处理请求都有各自的处理器。所有的请求都要经过各自的处理器。处理器会记录当前服务的请求失败率。一旦发现当前服务的请求失败率达到预设的值，Hystrix将会拒绝随后该服务的所有请求，直接返回一个预设的结果。这就是所谓的**“熔断”**。当经过一段时间后，Hystrix会放行该服务的一部分请求，再次统计它的请求失败率。如果此时请求失败率符合预设值，则完全打开限流开关；如果请求失败率仍然很高，那么继续拒绝该服务的所有请求。这就是所谓的**“限流”**。而Hystrix向那些被拒绝的请求直接返回一个预设结果，被称为**“降级”**。

##### 4、双写一致性

#### Redis过期策略

redis做缓存，因为，内存有限制，所以有过期替换策略。

##### key的有效期
- 会随着访问延长时间？**不对**
- 发生写，会剔除过期时间
- 倒计时，且，redis不能延长
- 定时

##### Maxmemory配置指令
`maxmemory`配置指令用于配置Redis存储数据时指定限制的内存大小。通过redis.conf可以设置该指令，或者之后使用CONFIG SET命令来进行运行时配置。

例如为了配置内存限制为100mb，以下的指令可以放在`redis.conf`文件中。

> maxmemory 100mb

设置`maxmemory`为0代表没有内存限制。64位的系统这是个默认值，32位的系统默认内存限制为3GB。

当指定的内存限制大小达到时，需要选择不同的行为，也就是**策略**。 Redis可以仅仅对命令返回错误，这将使得内存被使用得更多，或者回收一些旧的数据来使得添加数据时可以避免内存限制。

##### Redis如何淘汰过期的keys

##### **目的：稍微牺牲性能，保证redis性能为王！！！**

Redis keys过期有两种方式：**被动**和**主动**方式。

当一些客户端尝试访问它时，key会被发现并主动的过期。

当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。

具体就是Redis每秒10次做的事情：

1. 测试随机的20个keys进行相关过期检测。
2. 删除所有已经过期的keys。
3. 如果有多于25%的keys过期，重复步奏1.

这是一个平凡的概率算法，基本上的假设是，我们的样本是这个密钥控件，并且我们不断重复过期检测，直到过期的keys的百分百低于25%,这意味着，在任何给定的时刻，最多会清除1/4的过期keys。

##### 在复制AOF文件时如何处理过期

为了获得正确的行为而不牺牲一致性，当一个key过期，`DEL`将会随着AOF文字一起合成到所有附加的slaves。在master实例中，这种方法是集中的，并且不存在一致性错误的机会。

然而，当slaves连接到master时，不会独立过期keys（会等到master执行DEL命令），他们任然会在数据集里面存在，所以当slave当选为master时淘汰keys会独立执行，然后成为master。

### 五、Redis集群问题

#### 1. 单机、单节点、单实例存在问题

- 单点故障
- 容量有限
- 压力

#### 2. AKF，xyz三个方向做扩展，拆分

- **x** 轴 ：全量，镜像，备份
- **y** 轴 ：业务，功能，
- **z** 轴 ： 优先级，逻辑

#### 3、解决方案

##### 主从复制，主备 （需要人工维护）

**目的：** 主机是单点，对 **主** 做HA

##### 1）一变多，引入的问题：

###### 数据一致性的问题

- （**同步方式**）强一致性，等待从写入完毕，在返回客户端，降低了可用性，效率
- （异步方式）强一致性降级：
    - 容忍一部分数据丢失
    - （**数据最终一致性**）借助消息队列，主redis和kafka同步阻塞，将消息扔入消息队列，从redis从消息队列中读, 如果客户端读**从redis**的数据，中途数据可能不一致

##### 2）主从和主备的区别

- 主从：读写分离
- 主备：备用机，做备份，只在主上做操作

###### 哨兵机制

###### 监控机制，一般采用奇数个 **n**

只有 大于等于 **n/2 + 1** 个 才作为主

​ **缺陷：扩展性差**

###### 集群模式，解决容量问题

**y**轴：业务拆分，数据拆分，交集不多

**z**轴：数据无法拆分：

- hash + 取模（modular）：取模的值需要固定，**分布式情况下扩展性不行**
- random： 类似消息队列
- kemata一致性哈希算法：映射算法
    
    1、<data， node>同时参加运算
    
    2、规划一个环形–》哈希环
    
    一个环上有n个物理节点，用hash算法将物理节点分配在一个环上；
    
    存值时，计算数据的hash值，放入最近的物理节点上
    
    **优点：**添加物理节点，的确可以分担其他节点的压力，不会造成全局洗牌
    
    **缺点：** 新增节点导致一小部分的数据不能命中
    
    问题：
    
    1.没命中，redis击穿，压倒MySQL
    
    解决方案：每次取离我最近的两个物理节点的数据
    

**一致性哈希算法数据倾斜问题**，利用虚拟物理节点的方式；

计算哈希值时，加上一个数字在计算，会得到数个几点
